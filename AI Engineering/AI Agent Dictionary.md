# AI Agent Dictionary

![image](https://github.com/user-attachments/assets/b45f83dd-2983-4f0e-9312-db38194dfdfc)

Link nguồn: https://www.scribd.com/document/842293196/AI-Agent-Dictionary

---

![image](https://github.com/user-attachments/assets/c0444e26-0493-4272-aee0-0e264d403c03)

### **1. Autonomous Agent (Đại lý tự động)**

- **Mô tả**: **Autonomous Agent** là một hệ thống AI hoạt động độc lập mà không cần sự can thiệp của con người.
- **Chức năng**:
  - **Quan sát môi trường và thực hiện hành động**: Đại lý này có khả năng quan sát môi trường xung quanh và thực hiện hành động dựa trên những gì nó quan sát được.
  - **Thích nghi và học hỏi**: Nó có thể thích nghi và học hỏi từ các kinh nghiệm trong quá trình hoạt động để cải thiện hiệu suất.
  - **Ứng dụng**: **Autonomous Agent** được sử dụng trong các lĩnh vực như **robotics**, **gaming**, và **automation** (tự động hóa).
- **Quá trình hoạt động**:
  - **Nhận dữ liệu từ người dùng và sự kiện**.
  - **Phân tích và xử lý** thông qua các tác vụ và bộ công cụ được lập trình sẵn.
  - **Thực hiện hành động** dựa trên các kết quả phân tích và trạng thái của môi trường.

---

### **2. Belief-Desire-Intention (BDI) Model (Mô hình Tin tưởng - Mong muốn - Ý định)**

- **Mô tả**: **BDI Model** là một mô hình quyết định cho các đại lý AI, giúp đại lý hiểu và thực hiện các hành động dựa trên những gì nó biết (beliefs), những mục tiêu nó muốn đạt được (desires), và các hành động nó sẽ thực hiện để đạt được mục tiêu đó (intentions).
- **Cấu trúc mô hình**:
  - **Belief (Tin tưởng)**: Những gì đại lý biết về môi trường và tình huống xung quanh.
  - **Desire (Mong muốn)**: Mục tiêu hoặc kết quả mà đại lý muốn đạt được.
  - **Intention (Ý định)**: Các hành động mà đại lý quyết định thực hiện để đạt được các mong muốn của mình.
- **Cấu trúc hoạt động**:
  - **Sensors (Cảm biến)**: Đại lý thu thập thông tin từ môi trường xung quanh.
  - **Actuators (Chấp hành)**: Đại lý thực hiện các hành động dựa trên quyết định của mình.
  - **Môi trường**: Môi trường mà đại lý tương tác với, ảnh hưởng đến các quyết định và hành động của đại lý.

---

![image](https://github.com/user-attachments/assets/35414228-8067-4653-9876-cc6aa80db900)

### **3. Conversational Agent (Đại lý trò chuyện)**

- **Mô tả**: **Conversational Agent** là một hệ thống AI được sử dụng trong các chatbot hoặc trợ lý giọng nói như **ChatGPT**, **Siri**, **Alexa**.
- **Chức năng**:
  - **Hiểu ngôn ngữ tự nhiên**: Conversational Agent có khả năng hiểu và phản hồi các câu hỏi từ người dùng, sử dụng các công nghệ **NLP** (Natural Language Processing).
  - **Trả lời câu hỏi của người dùng**: Hệ thống này có thể trả lời câu hỏi của người dùng về nhiều lĩnh vực khác nhau.
  - **Ứng dụng**: Các ứng dụng phổ biến như **ChatGPT**, **Siri**, **Alexa**.
  - **Đặc điểm**: Hỗ trợ các **cuộc trò chuyện đa đại lý** (multi-agent conversations) với khả năng **tùy chỉnh đại lý** (agent customization) và **mô hình hội thoại linh hoạt** (flexible conversation patterns).

---

### **4. Decision Tree (Cây quyết định)**

- **Mô tả**: **Decision Tree** là một mô hình dạng sơ đồ cây được sử dụng trong **quyết định** AI.
- **Cấu trúc**:
  - **Cây quyết định** là một sơ đồ dạng cây mà mỗi nhánh đại diện cho một câu hỏi hoặc điều kiện, và các nhánh con đại diện cho kết quả hoặc hành động sau khi phân tích các điều kiện.
  - Ví dụ trong hình ảnh: **"Is a person fit?"** - cây quyết định sẽ đánh giá các điều kiện như tuổi tác và thói quen ăn uống hoặc tập thể dục để đưa ra quyết định.
- **Ứng dụng**:
  - **Phân tích dữ liệu và ra quyết định**: Đây là phương pháp phổ biến trong các hệ thống AI dựa trên **quy tắc** và giúp đưa ra quyết định nhanh chóng bằng cách chia nhỏ vấn đề thành các bước đơn giản.
  - **Ứng dụng trong AI quy tắc**: Thường được sử dụng trong các hệ thống AI sử dụng **"if-then" conditions** để ra quyết định.
- **Lợi ích**: Giúp đơn giản hóa và hình dung rõ ràng các quyết định dựa trên các yếu tố khác nhau.

---

![image](https://github.com/user-attachments/assets/561ac224-fd64-4f80-a557-01b78c624e7e)

### **5. Embodied AI (Trí tuệ nhân tạo có thể tương tác với thế giới thực)**

- **Mô tả**: **Embodied AI** là hệ thống AI có **hiện diện vật lý hoặc ảo**, có khả năng tương tác với thế giới thực hoặc với người dùng thông qua các **robot** hoặc **avatar trong metaverse**.
- **Cách thức hoạt động**:
  - **Nhận dạng môi trường**: Hệ thống có thể **nhận dạng** và phân tích môi trường xung quanh qua **camera** và **cảm biến**.
  - **Điều khiển robot**: AI có thể điều khiển robot vật lý hoặc avatar trong môi trường ảo để thực hiện các hành động như di chuyển hoặc tương tác với người dùng.
  - **Ứng dụng**:
    - **Robot**: Các robot có thể tương tác với con người trong các công việc thực tế như chăm sóc, sản xuất, v.v.
    - **Metaverse**: Avatar AI trong môi trường ảo có thể giúp người dùng tương tác và thực hiện các hành động trong thế giới ảo.
  - **Lợi ích**: Cải thiện **tương tác giữa con người và AI**, giúp AI không chỉ tồn tại trong phần mềm mà còn có thể thể hiện và tương tác trong thế giới vật lý hoặc ảo.

---

### **6. Federated Learning (Học tập phân tán)**

- **Mô tả**: **Federated Learning** là phương pháp học máy trong đó các **mô hình AI** học từ **dữ liệu phân tán** trên nhiều thiết bị mà không cần chia sẻ dữ liệu thô giữa các thiết bị.
- **Cách thức hoạt động**:
  - Các thiết bị như **laptop**, **điện thoại**, **thiết bị Edge** (thiết bị xử lý gần người dùng) có thể **học từ dữ liệu cục bộ** mà không cần gửi dữ liệu đó về máy chủ trung tâm.
  - Các mô hình học từ dữ liệu cục bộ sẽ **cập nhật trọng số mô hình** và chỉ gửi lại **trọng số mô hình đã cập nhật** lên máy chủ trung tâm, không cần chia sẻ dữ liệu thô.
- **Ứng dụng**:
  - **Bảo mật và quyền riêng tư**: Phương pháp này giúp **bảo vệ quyền riêng tư** của người dùng vì dữ liệu không bị chia sẻ.
  - **Ứng dụng trong y tế và AI di động**: Phương pháp này rất phù hợp cho các ứng dụng y tế và di động, nơi dữ liệu cần được bảo vệ nhưng vẫn phải học và cải thiện mô hình.
- **Lợi ích**:
  - **Bảo vệ quyền riêng tư** của người dùng.
  - **Không cần chia sẻ dữ liệu thô**, giúp bảo vệ dữ liệu nhạy cảm.
  - Thích hợp cho các ứng dụng yêu cầu dữ liệu phân tán và riêng tư.

---
![image](https://github.com/user-attachments/assets/5e4b12a9-f338-4c51-adbc-fc2ce06a6da3)

### **7. Goal-Oriented Agent (Đại lý hướng mục tiêu)**

- **Mô tả**: **Goal-Oriented Agent** là một hệ thống AI được thiết kế để hoàn thành một nhiệm vụ cụ thể.
- **Chức năng**:
  - **Tập trung vào hiệu quả**: Đại lý này sẽ cố gắng hoàn thành nhiệm vụ một cách tối ưu và hiệu quả.
  - **Học hỏi từ phản hồi**: Đại lý sẽ học từ các phản hồi nhận được trong quá trình thực hiện nhiệm vụ.
  - **Ví dụ**: **AI chơi cờ** hoặc **robot kho hàng**.
- **Quá trình hoạt động**:
  - **Nhận dữ liệu từ môi trường**: Đại lý nhận thông tin từ môi trường và sử dụng bộ công cụ cùng bộ nhớ để thực hiện các hành động.
  - **Hành động**: Sau khi nhận dữ liệu và phân tích, đại lý thực hiện hành động để đạt được mục tiêu của mình.
  - **Cải tiến qua feedback**: Đại lý có thể điều chỉnh hành động của mình dựa trên các phản hồi từ môi trường hoặc người dùng.

---

### **8. Heuristic Function (Hàm Heuristic)**

- **Mô tả**: **Heuristic Function** là một phương pháp rút gọn giúp đưa ra quyết định nhanh chóng trong AI.
- **Chức năng**:
  - **Tìm kiếm nhanh**: Phương pháp này giúp AI đưa ra quyết định nhanh chóng bằng cách sử dụng các **xấp xỉ**, thay vì tính toán chính xác từng bước.
  - **Ứng dụng phổ biến trong game AI**: Phương pháp này được sử dụng rộng rãi trong các trò chơi, nơi tốc độ ra quyết định là quan trọng hơn độ chính xác tuyệt đối.
- **Các kỹ thuật tìm kiếm heuristic**:
  - **Best-First Search**
  - **A* Search**
  - **Bidirectional Search**
  - **Tabu Search**
  - **Beam Search**
  - **Simulated Annealing**
  - **Hill Climbing**
  - **Constraint Satisfaction Problems (CSP)**

- **Lợi ích**:
  - **Sử dụng các xấp xỉ** để đưa ra quyết định nhanh chóng.
  - **Cân bằng giữa tốc độ và độ chính xác**.

---
![image](https://github.com/user-attachments/assets/4b3ea4c8-817a-4ca2-bbcd-4914fd813c93)

### **9. Intent Recognition (Nhận diện mục đích)**

- **Mô tả**: **Intent Recognition** là quá trình hiểu mục đích của người dùng trong các cuộc hội thoại. Nó rất quan trọng trong việc phát triển các **chatbot** và các ứng dụng xử lý ngôn ngữ tự nhiên (NLP).
- **Chức năng**:
  - **Hiểu mục đích người dùng**: Hệ thống phân tích câu hỏi và xác định mục đích của người dùng từ các cuộc trò chuyện.
  - **Cải thiện trải nghiệm người dùng**: Bằng cách nhận diện chính xác các mục tiêu, hệ thống có thể đưa ra các phản hồi chính xác hơn, cải thiện tương tác với người dùng.
  - **Ứng dụng**: Được sử dụng chủ yếu trong **chatbot**, như **ChatGPT**, **Siri**, **Alexa**, v.v.
- **Quá trình hoạt động**:
  1. **Input Data (Dữ liệu đầu vào)**: Người dùng nhập câu hỏi (ví dụ: "I am looking for a Mexican restaurant").
  2. **Process (Xử lý)**: Hệ thống sử dụng NLP và các dấu hiệu ngữ cảnh để phân tích và hiểu mục đích.
  3. **Classify (Phân loại)**: Hệ thống phân loại mục đích và đưa ra phản hồi chính xác, ví dụ: cung cấp danh sách các nhà hàng Mexico.

---

### **10. Joint Action Learning (Học hành động chung)**

- **Mô tả**: **Joint Action Learning** là phương pháp trong đó các đại lý AI học cách hợp tác với nhau để thực hiện các tác vụ chung.
- **Chức năng**:
  - **Học hợp tác**: Các đại lý AI học cách tương tác và phối hợp với nhau để hoàn thành các nhiệm vụ phức tạp.
  - **Ứng dụng trong hệ thống nhiều đại lý**: Phương pháp này được sử dụng trong các hệ thống nhiều đại lý (multi-agent systems) như **xe tự lái** hoặc **robot công nghiệp**.
- **Quá trình hoạt động**:
  - **Observation Encoding**: Các đại lý nhận thông tin từ môi trường và mã hóa chúng thành dữ liệu có thể sử dụng.
  - **Action Decoding**: Đại lý quyết định hành động dựa trên các thông tin đã nhận được và hành động theo cách tối ưu.
- **Ứng dụng**:
  - **Sử dụng trong các hệ thống nhiều đại lý**: Như các **xe tự lái** phải phối hợp với nhau để đảm bảo an toàn và hiệu quả trong việc di chuyển.
  - **Giúp giải quyết các tác vụ phối hợp**: Các đại lý học cách phối hợp và tối ưu hóa hành động chung, ví dụ trong các nhiệm vụ nhóm như giao hàng tự động, vận hành robot đồng thời.

---
![image](https://github.com/user-attachments/assets/76d2e12e-53ee-4662-8341-00f722f0922b)

### **11. Knowledge Graph (Biểu đồ tri thức)**

- **Mô tả**: **Knowledge Graph** là một mạng lưới thông tin liên kết với nhau, giúp kết nối các mối quan hệ giữa các dữ liệu khác nhau.
- **Chức năng**:
  - **Cải thiện lý luận của AI**: Knowledge Graph giúp hệ thống AI có thể phân tích và hiểu mối quan hệ giữa các yếu tố trong dữ liệu, từ đó đưa ra các quyết định và kết luận thông minh hơn.
  - **Ứng dụng trong công cụ tìm kiếm**: Knowledge Graph được sử dụng trong các công cụ tìm kiếm để cải thiện kết quả tìm kiếm và cung cấp thông tin chính xác hơn cho người dùng.
  - **Ví dụ nổi tiếng**: **Google's Knowledge Graph** là một ví dụ điển hình, giúp Google cung cấp kết quả tìm kiếm chính xác hơn và hiểu ngữ nghĩa của các câu hỏi.
- **Quá trình hoạt động**:
  - **Xử lý văn bản không có cấu trúc**: Knowledge Graph sử dụng các tài liệu không có cấu trúc (unstructured documents), ví dụ như bài viết trên web, để tạo ra các biểu đồ tri thức.
  - **Tạo và truy vấn đồ thị tri thức**: Sau khi trích xuất thông tin từ các tài liệu, hệ thống sẽ tạo ra **Ontology** (mô hình tri thức) và sử dụng **LLM** để tạo đồ thị tri thức và truy vấn dữ liệu.
  
---

### **12. Large Language Model (LLM) - Mô hình ngôn ngữ lớn**

- **Mô tả**: **Large Language Model (LLM)** là một mô hình AI được huấn luyện trên một lượng lớn dữ liệu văn bản để hiểu và sinh ra văn bản giống con người.
- **Chức năng**:
  - **Sinh văn bản giống con người**: LLM có khả năng tạo ra văn bản tự nhiên, trả lời câu hỏi, viết mã, v.v.
  - **Trả lời câu hỏi và viết mã**: Các mô hình này có thể trả lời các câu hỏi dựa trên kiến thức đã học và thậm chí viết mã lập trình.
  - **Ví dụ**: Các mô hình như **GPT-4**, **Claude**, **Gemini** đều là các ví dụ của LLM.
- **Quá trình hoạt động**:
  - **Tokenization**: Quá trình phân tách dữ liệu đầu vào thành các phần nhỏ (tokens) để xử lý.
  - **Embedding Layer**: Chuyển các tokens thành các vector đại diện.
  - **Transformer Blocks**: Xử lý và phân tích dữ liệu qua các lớp transformer, với hai cơ chế chính là **Self-Attention** và **Feed-Forward**.
  - **Self-Attention**: Giúp mô hình hiểu và liên kết các từ trong văn bản với nhau để tạo ra mối quan hệ và ngữ cảnh.
  - **Feed-Forward**: Quá trình đưa dữ liệu qua các lớp mạng để tối ưu hóa và học từ dữ liệu.
  - **Training & Loss Optimization**: Quá trình huấn luyện và tối ưu hóa mô hình bằng cách điều chỉnh các tham số để giảm thiểu sai số (loss).

---
![image](https://github.com/user-attachments/assets/1e8b6f3f-67ff-41ee-9d2e-8573978aec98)

### **13. Multi-Agent System (MAS) - Hệ thống đa đại lý**

- **Mô tả**: **Multi-Agent System (MAS)** là một hệ thống gồm nhiều đại lý AI làm việc cùng nhau để đạt được mục tiêu chung.
- **Chức năng**:
  - **Ra quyết định phân tán**: Các đại lý trong hệ thống có thể đưa ra quyết định độc lập mà không cần sự can thiệp của một hệ thống trung tâm.
  - **Ứng dụng**:
    - Được sử dụng trong các **mô phỏng**, **bot giao dịch**, nơi nhiều đại lý cần làm việc cùng nhau để tối ưu hóa kết quả.
    - **Cảm hứng từ hành vi đàn**: MAS thường được lấy cảm hứng từ hành vi của các đàn động vật, ví dụ như đàn chim hoặc đàn cá, nơi mỗi thành viên trong đàn làm việc cùng nhau để đạt mục tiêu chung.
- **Cấu trúc hoạt động**:
  - **Agent Orchestration**: Quản lý và điều phối các đại lý để làm việc cùng nhau, tương tác với người dùng và các công cụ bên ngoài.
  - **Chat & Control**: Các đại lý giao tiếp và trao đổi thông tin với nhau, đôi khi có sự điều phối của con người.
  - **Ứng dụng trong các lĩnh vực** như **robot công nghiệp**, **giao dịch tài chính tự động**, và **chatbots đa đại lý**.

---

### **14. Neural-Symbolic AI - Trí tuệ nhân tạo kết hợp mạng nơ-ron và biểu tượng**

- **Mô tả**: **Neural-Symbolic AI** là sự kết hợp giữa **học sâu** (deep learning) và **lý luận biểu tượng** (symbolic reasoning).
- **Chức năng**:
  - **Kết nối mạng nơ-ron và AI biểu tượng**: **Neural-Symbolic AI** kết hợp khả năng học của mạng nơ-ron với khả năng lý luận logic của AI biểu tượng, giúp AI có khả năng hiểu và lý luận giống như con người.
  - **Tăng cường khả năng giải thích**: Cải thiện khả năng giải thích và đưa ra lý do cho các quyết định AI, rất hữu ích trong các lĩnh vực như **pháp lý** và **khoa học**.
- **Ứng dụng**:
  - **Pháp lý và khoa học**: Trong các hệ thống AI cho phép ra quyết định và lý luận trong các tình huống phức tạp, như xử lý các trường hợp pháp lý hoặc nghiên cứu khoa học.
- **Lợi ích**:
  - **Interpretability (Khả năng giải thích)**: Neural-Symbolic AI giúp tăng khả năng giải thích các quyết định của AI.
  - **Data Efficiency (Hiệu quả dữ liệu)**: Sử dụng ít dữ liệu hơn trong quá trình huấn luyện so với các phương pháp học sâu thuần túy.
  - **Generalizability (Khả năng tổng quát)**: Mô hình này có thể hoạt động tốt trên nhiều loại dữ liệu khác nhau.
  - **Robustness (Độ bền vững)**: Cải thiện độ ổn định và khả năng chống lại các yếu tố thay đổi trong môi trường.

---
![image](https://github.com/user-attachments/assets/2d7504b9-17ed-44a2-82bd-645b6a5232b7)

### **15. Online Learning (Học trực tuyến)**

- **Mô tả**: **Online Learning** là một phương pháp học trong đó AI liên tục cập nhật kiến thức từ dữ liệu thực tế và thích nghi với môi trường thay đổi.
- **Chức năng**:
  - **Học từ dữ liệu thời gian thực**: AI có thể học từ các dữ liệu mới và cập nhật kiến thức của mình liên tục mà không cần phải huấn luyện lại từ đầu.
  - **Thích nghi với môi trường thay đổi**: Hệ thống có thể tự động điều chỉnh khi có sự thay đổi trong dữ liệu hoặc môi trường.
  - **Ứng dụng**: Phương pháp này thường được sử dụng trong **hệ thống khuyến nghị**, như Netflix hoặc Amazon, để cải thiện các đề xuất cho người dùng dựa trên hành vi của họ.
- **Quá trình hoạt động**:
  - **Sensors** (Cảm biến) thu thập thông tin từ môi trường.
  - **Critic** đưa ra phản hồi dựa trên tiêu chuẩn hiệu suất.
  - **Learning Element** sử dụng các phản hồi này để cải thiện mô hình và cập nhật kiến thức.
  - **Problem Generator** và **Performance Element** giúp AI tạo ra các bài học và tối ưu hóa hiệu suất.

---

### **16. Proactive Agent (Đại lý chủ động)**

- **Mô tả**: **Proactive Agent** là một hệ thống AI có khả năng dự đoán và giải quyết nhu cầu của người dùng trước khi họ yêu cầu.
- **Chức năng**:
  - **Đưa ra quyết định chủ động**: Proactive Agent không chỉ thực hiện các yêu cầu từ người dùng mà còn tự động nhận diện và thực hiện các tác vụ cần thiết trước khi người dùng yêu cầu.
  - **Cải thiện hiệu quả tự động hóa**: Với khả năng chủ động, Proactive Agent giúp tối ưu hóa quy trình và nâng cao hiệu quả công việc.
  - **Ứng dụng**: Các **trợ lý thông minh** như Siri, Google Assistant, hoặc các ứng dụng quản lý công việc sử dụng Proactive Agent để tự động lên lịch các cuộc họp, nhắc nhở, hoặc thực hiện các nhiệm vụ khác mà không cần người dùng yêu cầu.
- **Quá trình hoạt động**:
  - **Nhận diện yêu cầu tiềm năng**: Proactive Agent có thể dự đoán nhu cầu của người dùng, ví dụ như giúp người dùng lên lịch cuộc họp trước khi họ yêu cầu.
  - **Phản hồi tự động**: Sau khi nhận diện yêu cầu, đại lý chủ động hành động mà không cần sự chỉ đạo từ người dùng.

---
![image](https://github.com/user-attachments/assets/24956f8c-5794-4ec9-ae34-f8a25aac9a38)

### **17. Q-Learning**

- **Mô tả**: **Q-Learning** là một phương pháp học củng cố (reinforcement learning) trong đó AI học thông qua thử và sai.
- **Chức năng**:
  - **Học qua thử và sai**: AI sẽ thử nhiều hành động khác nhau và nhận phản hồi từ môi trường để tối ưu hóa quyết định của mình.
  - **Sử dụng phần thưởng để cải thiện quyết định**: Khi AI thực hiện một hành động và nhận được phần thưởng, nó sẽ học từ phần thưởng đó để đưa ra các quyết định tốt hơn trong tương lai.
  - **Cốt lõi của AI tự học**: Q-Learning là phương pháp cơ bản trong các hệ thống AI tự học, nơi AI có thể cải thiện hiệu suất theo thời gian mà không cần sự can thiệp của con người.
- **Quá trình hoạt động**:
  - **Q-function updating agent**: AI cập nhật các giá trị Q (từ các hành động) để tối ưu hóa quyết định.
  - **Reward evaluation**: Mỗi hành động có một **phần thưởng** và AI đánh giá hành động này để cải thiện chiến lược.
  - **Most favorite action**: AI sẽ chọn hành động yêu thích nhất dựa trên phần thưởng đã nhận được từ các hành động trước đó.
  - **Ứng dụng**: Được sử dụng rộng rãi trong các bài toán như **game AI**, **robotics**, và các **hệ thống tự học**.

---

### **18. Reinforcement Learning (RL) Agent**

- **Mô tả**: **Reinforcement Learning (RL)** là một phương pháp học máy trong đó AI học cách tối ưu hóa hành động của mình để nhận được **phần thưởng** tối đa.
- **Chức năng**:
  - **Học bằng cách tối đa hóa phần thưởng**: AI học cách đưa ra các hành động đúng đắn để nhận được phần thưởng càng lớn càng tốt.
  - **Cải thiện theo thời gian**: Theo thời gian, AI sẽ học cách thực hiện các hành động tốt hơn để tối ưu hóa kết quả.
  - **Ứng dụng**: **RL** được sử dụng trong nhiều lĩnh vực như **robotics**, **game AI** và đặc biệt là trong các ứng dụng như **AlphaGo**.
- **Quá trình hoạt động**:
  - **Agent** thực hiện **hành động** trong môi trường.
  - **Môi trường** phản hồi lại với **phần thưởng** và thay đổi **trạng thái**.
  - AI sử dụng **phần thưởng** để học hỏi và cải thiện hành động của mình trong lần tiếp theo.

---
![image](https://github.com/user-attachments/assets/f51039b8-1b69-4ddd-ae48-7d7d0526a124)

### **19. Swarm Intelligence (Trí tuệ bầy đàn)**

- **Mô tả**: **Swarm Intelligence** là hệ thống AI lấy cảm hứng từ hành vi tập thể trong tự nhiên, đặc biệt là từ các loài động vật như **kiến**, **ong** và **chim**.
- **Chức năng**:
  - **Giải quyết vấn đề phân tán**: Hệ thống giải quyết vấn đề mà không cần một trung tâm chỉ huy. Mỗi cá thể trong "bầy" làm việc độc lập nhưng phối hợp để đạt được mục tiêu chung.
  - **Ứng dụng**:
    - **Lịch trình hóa**: Tối ưu hóa lịch trình cho các hoạt động hoặc tài nguyên.
    - **Tối ưu hóa**: Cải thiện hiệu suất và giảm chi phí trong các hệ thống phức tạp.
    - **Phân nhóm (Clustering)**: Tự động nhóm các đối tượng hoặc dữ liệu theo các đặc điểm chung.
    - **Định tuyến (Routing)**: Tối ưu hóa các tuyến đường di chuyển, ví dụ như trong vận chuyển hoặc giao thông.
  - **Ứng dụng trong**:
    - **Logistics**: Quản lý và tối ưu hóa quá trình vận chuyển.
    - **Kiểm soát giao thông**: Điều phối giao thông hiệu quả bằng cách học hỏi từ hành vi bầy đàn.

---

### **20. Task-Oriented Dialogue System (Hệ thống đối thoại theo nhiệm vụ)**

- **Mô tả**: **Task-Oriented Dialogue System** là một hệ thống AI được thiết kế để thực hiện các nhiệm vụ cụ thể, chẳng hạn như đặt vé máy bay, hỗ trợ khách hàng, v.v.
- **Chức năng**:
  - **Tối ưu hóa cho hiệu quả**: Hệ thống được tối ưu để xử lý các nhiệm vụ cụ thể nhanh chóng và hiệu quả.
  - **Giới hạn trong một miền**: Hệ thống này chỉ hoạt động trong các lĩnh vực hoặc nhiệm vụ xác định, ví dụ như **đặt vé máy bay** hoặc **hỗ trợ khách hàng**.
  - **Ứng dụng**:
    - **Các bot hỗ trợ khách hàng**: Hệ thống có thể giúp khách hàng giải quyết các vấn đề như tra cứu thông tin sản phẩm, xử lý yêu cầu hỗ trợ, v.v.
- **Quá trình hoạt động**:
  - **Nhận dạng ngôn ngữ tự nhiên (NLP)**: Hệ thống hiểu yêu cầu từ người dùng, ví dụ: "Tôi muốn tìm một nhà hàng Trung Quốc."
  - **Theo dõi trạng thái đối thoại**: Hệ thống theo dõi và cập nhật trạng thái đối thoại để hiểu rõ yêu cầu của người dùng.
  - **Quản lý đối thoại**: Dựa trên các thông tin đã thu thập, hệ thống tìm kiếm và trả lời thông qua cơ sở dữ liệu hoặc kiến thức có sẵn.

---
![image](https://github.com/user-attachments/assets/d89adb9f-2e99-4461-afea-63d86389e4f5)

### **21. Utility-Based Agent (Đại lý dựa trên tiện ích)**

- **Mô tả**: **Utility-Based Agent** là một hệ thống AI lựa chọn hành động dựa trên **tiện ích cao nhất**, với mục tiêu tối ưu hóa hiệu suất công việc.
- **Chức năng**:
  - **Tối đa hóa hiệu suất**: Đại lý này chọn hành động giúp tối đa hóa **tiện ích**, từ đó đạt được hiệu quả tối ưu nhất.
  - **Đánh giá sự đánh đổi**: Hệ thống sẽ phân tích và đánh giá các sự đánh đổi giữa các hành động khác nhau để chọn ra hành động mang lại tiện ích cao nhất.
  - **Ứng dụng**:
    - **Kinh tế học**: Được sử dụng để tối ưu hóa các quyết định trong kinh tế.
    - **Robot học**: Được áp dụng trong các hệ thống robot tự động, giúp robot ra quyết định tối ưu.
- **Quá trình hoạt động**:
  - **Nhận thông tin từ cảm biến**: Các cảm biến cung cấp dữ liệu môi trường (ví dụ: trạng thái hiện tại).
  - **Đánh giá tiện ích**: Hệ thống đánh giá mức độ **tiện ích** của các hành động khác nhau.
  - **Thực hiện hành động**: Hệ thống chọn hành động với tiện ích cao nhất và thực hiện nó để tối ưu hóa hiệu suất.

---

### **22. Virtual Agent (Đại lý ảo)**

- **Mô tả**: **Virtual Agent** là các nhân vật AI được điều khiển bởi máy tính, có thể là **avatar** 2D hoặc 3D, tương tác trong thế giới ảo.
- **Chức năng**:
  - **Tương tác trong thế giới ảo**: Virtual Agent có thể giao tiếp và thực hiện các tác vụ trong các môi trường ảo, như **trò chơi điện tử**, **mô phỏng huấn luyện**, v.v.
  - **Ứng dụng**:
    - **Game**: Virtual Agent có thể được sử dụng trong các trò chơi điện tử, nơi nó giúp tạo ra các nhân vật ảo hoặc NPC (Non-Player Character) tương tác với người chơi.
    - **Mô phỏng huấn luyện**: Các agent này được sử dụng trong các mô phỏng huấn luyện để tạo ra một môi trường tương tác, giúp người học trải nghiệm và thực hành các tình huống thực tế trong một môi trường an toàn.
- **Công nghệ sử dụng**:
  - **Text-to-Speech** và **Speech-to-Text**: Virtual Agent có thể sử dụng các công nghệ nhận dạng giọng nói và chuyển văn bản thành giọng nói, giúp tạo ra các cuộc trò chuyện tự nhiên với người dùng.
  - **Microsoft Power Virtual Agent**: Cung cấp các công cụ để tạo các Virtual Agent và triển khai trong các kênh giao tiếp.

---
![image](https://github.com/user-attachments/assets/f763661a-1e50-473c-a842-7bd4ec828d53)

### **23. Weighted Action Selection (Lựa chọn hành động có trọng số)**

- **Mô tả**: **Weighted Action Selection** là một kỹ thuật trong AI dùng để ưu tiên các quyết định của AI, bằng cách gán trọng số cho các hành động khác nhau.
- **Chức năng**:
  - **Gán trọng số cho các hành động**: AI sẽ đánh giá và gán trọng số cho từng hành động để xác định hành động nào có giá trị cao hơn.
  - **Cân bằng giữa rủi ro và phần thưởng**: Kỹ thuật này giúp AI đánh giá sự đánh đổi giữa các hành động có rủi ro thấp và phần thưởng cao, giúp tối ưu hóa quyết định.
  - **Ứng dụng trong AI chiến lược**: Phương pháp này được sử dụng trong các ứng dụng **AI chiến lược** (strategic AI), nơi AI phải đưa ra quyết định có tính toán kỹ lưỡng như trong các trò chơi chiến lược, hoặc các hệ thống tự động hóa phức tạp.
- **Quá trình hoạt động**:
  - **Input Layer**: Nhận dữ liệu đầu vào.
  - **Hidden Layers**: Qua các lớp ẩn, hệ thống xử lý thông tin và tính toán trọng số của các hành động.
  - **Output Layer**: Hành động được lựa chọn dựa trên trọng số cao nhất.
  
---

### **24. Explainable AI (XAI) - Trí tuệ nhân tạo có thể giải thích**

- **Mô tả**: **Explainable AI (XAI)** là một phương pháp AI cung cấp lý luận có thể hiểu được bởi con người, giúp giải thích các quyết định mà AI đưa ra.
- **Chức năng**:
  - **Giảm vấn đề "hộp đen" trong AI**: Trí tuệ nhân tạo thường bị chỉ trích vì không thể giải thích rõ ràng các quyết định của nó, gọi là vấn đề "hộp đen". XAI giúp giải quyết vấn đề này bằng cách cung cấp các giải thích dễ hiểu.
  - **Quan trọng cho sự tin tưởng và đạo đức**: XAI giúp người dùng tin tưởng vào các quyết định của AI, đặc biệt là trong các lĩnh vực nhạy cảm như **y tế** và **tài chính**.
  - **Ứng dụng trong y tế và tài chính**: XAI giúp các chuyên gia trong lĩnh vực này hiểu rõ lý do mà AI đưa ra các quyết định về sức khỏe hoặc các giao dịch tài chính.
- **Quá trình hoạt động**:
  - **Dữ liệu đầu vào (Input Data)**: Dữ liệu được cung cấp cho hệ thống AI.
  - **Mô hình học máy (ML Model)**: Mô hình AI phân tích và đưa ra dự đoán.
  - **Giải thích (Explanations)**: XAI sẽ cung cấp các giải thích dễ hiểu cho người dùng về lý do mà AI đưa ra dự đoán hoặc quyết định.
  - **Giao diện người dùng (User Interface)**: Cung cấp các giải thích trực quan và dễ hiểu cho người dùng và các chuyên gia.

---
![image](https://github.com/user-attachments/assets/c4df21a9-b4bc-43b2-8f27-22ac2823a601)

### **25. Yield Optimization (Tối ưu hóa hiệu suất)**

- **Mô tả**: **Yield Optimization** là quá trình tối đa hóa sự liên quan và hiệu quả của đầu ra, đặc biệt trong các mô hình đã được tinh chỉnh (fine-tuned).
- **Chức năng**:
  - **Cải thiện chất lượng phản hồi**: Phương pháp này giúp cải thiện độ chính xác của các mô hình AI đã được tinh chỉnh, giúp hệ thống phản hồi một cách chính xác và hiệu quả hơn.
  - **Điều chỉnh và theo dõi liên tục**: Quá trình tối ưu hóa này bao gồm các bước **điều chỉnh lặp đi lặp lại** và **theo dõi hiệu suất** của hệ thống trong thời gian thực.
  - **Cải thiện sự hài lòng của người dùng**: Quá trình tối ưu hóa giúp đảm bảo rằng người dùng nhận được kết quả chính xác và hài lòng với trải nghiệm thực tế.
- **Quá trình hoạt động**:
  1. **Máy dạy (Machine teaching)**: Bắt đầu quá trình với việc dạy máy các quy trình và chiến lược ban đầu.
  2. **Chiến lược huấn luyện/phần thưởng**: Đưa ra các chiến lược huấn luyện và phương pháp đánh giá để tối ưu hóa kết quả.
  3. **Huấn luyện AI (Reinforcement learning)**: AI tiếp tục học và điều chỉnh chiến lược của mình.
  4. **Xác minh ảo (Virtual validation)**: Đánh giá kết quả trong môi trường mô phỏng.
  5. **Triển khai thử nghiệm (Deployment trials)**: Tiến hành thử nghiệm để kiểm tra hiệu quả.
  6. **Triển khai sản xuất**: Cuối cùng, triển khai mô hình trong môi trường thực tế.

---

### **26. Zero-shot Learning (Học không cần tinh chỉnh)**

- **Mô tả**: **Zero-shot Learning** là phương pháp học trong đó AI thực hiện các nhiệm vụ mà không cần tinh chỉnh đặc thù cho mỗi nhiệm vụ.
- **Chức năng**:
  - **Tận dụng kiến thức chung**: AI sử dụng kiến thức đã được huấn luyện trước để thực hiện các nhiệm vụ mới mà không cần phải huấn luyện lại cho từng nhiệm vụ cụ thể.
  - **Thích ứng nhanh chóng**: Zero-shot learning giúp AI nhanh chóng thích nghi với các miền dữ liệu hoặc nhiệm vụ mới mà không cần tinh chỉnh phức tạp.
  - **Đặc điểm của các mô hình LLM (Large Language Models) tiên tiến**: Đây là một tính năng quan trọng của các mô hình ngôn ngữ lớn (LLM), giúp mô hình trả lời câu hỏi, phân loại, và thực hiện các nhiệm vụ mới mà không cần huấn luyện lại.
- **Quá trình hoạt động**:
  - **Sử dụng không gian nhúng ngữ nghĩa** (Semantic Embedding Space): Mô hình học từ các dữ liệu đã thấy trước (seen) và sau đó có thể xử lý các dữ liệu chưa thấy (unseen), như hình ảnh động vật chưa biết trong các lớp học khác.
  - **Ứng dụng**:
    - **Phân loại hình ảnh động vật**: Ví dụ, AI có thể phân loại **chó** và **mèo** mà không cần huấn luyện thêm dữ liệu về chúng, vì đã học được mối quan hệ giữa các loài động vật trong không gian nhúng ngữ nghĩa.

---
